x = "Year",
y = "Stock Index Buzz")
# Stock Index Fear
fear_df <- combined_df %>%
filter(year(date) >= 1998) %>%
select(date, country, "Stock.Index.Fear")
plot_index_fear <- ggplot(fear_df, aes(x = date, y = `Stock.Index.Fear`, color = country)) +
geom_line() +
scale_color_manual(values=c("pink", "red", "green", "orange", "grey", "purple", "blue")) +
scale_x_date(date_breaks = "5 years", date_labels = "%Y") +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
legend.position="bottom",
panel.background = element_rect(fill = "white", colour = "white"),
panel.border = element_rect(colour = "black", fill=NA, linewidth=1),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
labs(title = "Stock Index Fear across G7",
x = "Year",
y = "Stock Index Fear")
ggsave("C:/Data/Illustration/Stock_Index_Buzz_Plot.png", plot = plot_index_buzz, width = 14, height = 8, dpi = 300)
ggsave("C:/Data/Illustration/Stock_Index_Fear_Plot.png", plot = plot_index_fear, width = 14, height = 8, dpi = 300)
plot_index_sentiment <- ggplot(sentiment_df, aes(x = date, y = `Stock.Index.Sentiment`, color = country)) +
geom_line() +
scale_color_manual(values=c("pink", "red", "green", "orange", "grey", "purple", "blue")) +
scale_x_date(date_breaks = "5 years", date_labels = "%Y", limits = as.Date(c("2000-01-28", NA))) + # Set scale to start from 2000
theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14),
legend.title = element_text(size = 12),
legend.text = element_text(size = 12),
legend.position = "bottom",
legend.direction = "horizontal",  # Display legend items in parallel
panel.background = element_rect(fill = "white", colour = "white"),
panel.border = element_rect(colour = "black", fill=NA, linewidth=1),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
labs(title = "Stock Index Sentiment across G7",
x = "Year",
y = "Stock Index Sentiment")
ggsave("C:/Data/Illustration/Stock_Index_Sentiment_Plot.png", plot = plot_index_sentiment, width = 14, height = 8, dpi = 300)
library(readxl)
library(writexl)
library(ggplot2)
library(tidyverse)
library(lubridate)
############################################# Illustrate Investor Sentiment Indexes ##########################################
SI_file <- "C:/Data/Sentiment Indexes/Sentiment_Index.xlsx"
# Read all sheets
sheet_names <- excel_sheets(SI_file)
for (sheet in sheet_names) {
df <- read_excel(SI_file, sheet = sheet)
write.csv(df, paste0("C:/Data/Sentiment Indexes/", sheet, ".csv"), row.names = FALSE)
}
# Initialize an empty list to store data
data_list <- list()
for (sheet in sheet_names) {
df <- read.csv(paste0("C:/Data/Sentiment Indexes/", sheet, ".csv"))
df$date <- ymd(paste0(df$date, "28")) # Convert yyyymm to Date format (28 as dd presenting the last trading date)
df$country <- sheet
data_list[[sheet]] <- df
}
# Combine all data frames into one
combined_df <- bind_rows(data_list)
# Stock Index Sentiment, limits = as.Date(c("2000-01-28", NA))
sentiment_df <- combined_df %>%
filter(year(date) >= 1998) %>% # Start from sample period
select(date, country, "Stock.Index.Sentiment")
plot_index_sentiment <- ggplot(sentiment_df, aes(x = date, y = `Stock.Index.Sentiment`, color = country)) +
geom_line() +
scale_color_manual(values=c("pink", "red", "green", "orange", "grey", "purple", "blue")) +
scale_x_date(date_breaks = "5 years", date_labels = "%Y") + # Set scale to start from 2000
theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14),
legend.title = element_text(size = 12),
legend.text = element_text(size = 12),
legend.position = "bottom",
legend.direction = "horizontal",  # Display legend items in parallel
panel.background = element_rect(fill = "white", colour = "white"),
panel.border = element_rect(colour = "black", fill=NA, linewidth=1),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
labs(title = "Stock Index Sentiment across G7",
x = "Year",
y = "Stock Index Sentiment")
ggsave("C:/Data/Illustration/Stock_Index_Sentiment_Plot.png", plot = plot_index_sentiment, width = 14, height = 8, dpi = 300)
sentiment_df <- combined_df %>%
filter(year(date) >= 1998) %>% # Start from sample period
select(date, country, "Stock.Index.Sentiment")
plot_index_sentiment <- ggplot(sentiment_df, aes(x = date, y = `Stock.Index.Sentiment`, color = country)) +
geom_line() +
scale_color_manual(values=c("pink", "red", "green", "orange", "grey", "purple", "blue")) +
scale_x_date(date_breaks = "2 years", date_labels = "%Y") +
theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14),
legend.title = element_text(size = 12),
legend.text = element_text(size = 12),
legend.position = "bottom",
legend.direction = "horizontal",  # Display legend items in parallel
panel.background = element_rect(fill = "white", colour = "white"),
panel.border = element_rect(colour = "black", fill=NA, linewidth=1),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
labs(title = "Stock Index Sentiment across G7",
x = "Year",
y = "Stock Index Sentiment")
ggsave("C:/Data/Illustration/Stock_Index_Sentiment_Plot.png", plot = plot_index_sentiment, width = 14, height = 8, dpi = 300)
plot_index_sentiment <- ggplot(sentiment_df, aes(x = date, y = `Stock.Index.Sentiment`, color = country)) +
geom_line() +
scale_color_manual(values=c("pink", "red", "green", "orange", "grey", "purple", "blue")) +
scale_x_date(date_breaks = "2 years", date_labels = "%Y") +
theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14),
legend.title = element_text(size = 12),
legend.text = element_text(size = 12),
legend.position = "bottom",
legend.direction = "horizontal",  # Display legend items in parallel
panel.background = element_rect(fill = "white", colour = "white"),
panel.border = element_rect(colour = "black", fill=NA, linewidth=1),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
labs(title = "Stock Index Sentiment across G7",
x = "Year",
y = "Stock Index Sentiment") +
guides(color = guide_legend(nrow = 1, byrow = TRUE))
ggsave("C:/Data/Illustration/Stock_Index_Sentiment_Plot.png", plot = plot_index_sentiment, width = 14, height = 8, dpi = 300)
buzz_df <- combined_df %>%
filter(year(date) >= 1998) %>%
select(date, country, "Stock.Index.Buzz")
plot_index_buzz <- ggplot(buzz_df, aes(x = date, y = `Stock.Index.Buzz`, color = country)) +
geom_line() +
scale_color_manual(values=c("pink", "red", "green", "orange", "grey", "purple", "blue")) +
scale_x_date(date_breaks = "2 years", date_labels = "%Y") +
theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14),
legend.title = element_text(size = 12),
legend.text = element_text(size = 12),
legend.position = "bottom",
legend.direction = "horizontal",
panel.background = element_rect(fill = "white", colour = "white"),
panel.border = element_rect(colour = "black", fill=NA, linewidth=1),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
labs(title = "Stock Index Buzz across G7",
x = "Year",
y = "Stock Index Buzz") +
guides(color = guide_legend(nrow = 1, byrow = TRUE))
# Stock Index Fear
fear_df <- combined_df %>%
filter(year(date) >= 1998) %>%
select(date, country, "Stock.Index.Fear")
plot_index_fear <- ggplot(fear_df, aes(x = date, y = `Stock.Index.Fear`, color = country)) +
geom_line() +
scale_color_manual(values=c("pink", "red", "green", "orange", "grey", "purple", "blue")) +
scale_x_date(date_breaks = "2 years", date_labels = "%Y") +
theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14),
legend.title = element_text(size = 12),
legend.text = element_text(size = 12),
legend.position = "bottom",
legend.direction = "horizontal",
panel.background = element_rect(fill = "white", colour = "white"),
panel.border = element_rect(colour = "black", fill=NA, linewidth=1),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
labs(title = "Stock Index Fear across G7",
x = "Year",
y = "Stock Index Fear") +
guides(color = guide_legend(nrow = 1, byrow = TRUE))
setwd("C:/Data/Illustration")
ggsave("C:/Data/Illustration/Stock_Index_Sentiment_Plot.png", plot = plot_index_sentiment, width = 14, height = 8, dpi = 300)
ggsave("C:/Data/Illustration/Stock_Index_Buzz_Plot.png", plot = plot_index_buzz, width = 14, height = 8, dpi = 300)
ggsave("C:/Data/Illustration/Stock_Index_Fear_Plot.png", plot = plot_index_fear, width = 14, height = 8, dpi = 300)
USA_mispricing <- fread("C:/Data/Mispricing/usa_mispricing.csv")
# 1. Set the required sample period (All anomalies from 196507 to 200801, but OSCORE and ROA from 197201)
USA_mispricing_Period <- USA_mispricing[USA_mispricing$eom >= 19650731 & USA_mispricing$eom <= 20080131 & !USA_mispricing$size_grp %in% c("micro", "nano"), ]
USA_mispricing_Period[eom < 19720131, c("o_score", "niq_at") := .(NA_real_, NA_real_)]
# 2. Set the required sample period (All anomalies from 199801 to 202012)
#USA_mispricing_Period <- USA_mispricing[USA_mispricing$eom >= 19980131 & USA_mispricing$eom <= 20201231 & !USA_mispricing$size_grp %in% c("micro", "nano"), ]
#colnames(USA_mispricing_Period)
setnames(USA_mispricing_Period, old = c(  "me",    "me_lag1",   "ret",    "o_score",     "ret_12_1",     "gp_at", "niq_at",  "chcsho_12m",        "eqnpo_12m",     "oaccruals_at",     "noa_at",          "at_gr1",      "ppeinv_gr1a"),
new = c("MV_USD", "LagMV_USD", "RET_USD", "O_Score", "MomentumReturn", "GPtoAsset", "ROA", "NetStockIssues", "CompositeEquity_Log", "Accruals", "NetOperatingAssets",  "AssetGrowth", "InvestmentToAsset"))
US_Data_long_ST <- USA_mispricing_Period[,.(id, eom, size_grp, MV_USD, LagMV_USD, RET_USD,
GPtoAsset, ROA, AssetGrowth, NetOperatingAssets, Accruals, InvestmentToAsset,
NetStockIssues, CompositeEquity_Log, MomentumReturn, O_Score)]
US_Data_long_ST[, date := format(as.Date(as.character(eom), "%Y%m%d"), "%Y%m")]
US_Data_long_ST[, eom := NULL]
View(US_Data_long_ST)
normalize_range <- function(x) {
output <- (x - min(x, na.rm = T)) / ( max(x, na.rm = T) - min(x, na.rm = T))
return(output)
}
total_mispricing <- function(Data) {
# Calculation of normalized ranks
Data[, GPtoAsset_Rank := normalize_range(rank(-GPtoAsset, na.last="keep", ties.method = "min")), by = date]
Data[GPtoAsset_Rank == Inf | GPtoAsset_Rank == -Inf, GPtoAsset_Rank := NA]
Data[, ROA_Rank := normalize_range(rank(-ROA, na.last="keep", ties.method = "min")), by = date]
Data[ROA_Rank == Inf | ROA_Rank == -Inf, ROA_Rank := NA]
Data[, AssetGrowth_Rank := normalize_range(rank(AssetGrowth, na.last="keep", ties.method = "max")), by = date]
Data[AssetGrowth_Rank == Inf | AssetGrowth_Rank == -Inf, AssetGrowth_Rank := NA]
Data[, NetOperatingAssets_Rank := normalize_range(rank(NetOperatingAssets, na.last="keep", ties.method = "max")), by = date]
Data[NetOperatingAssets_Rank == Inf | NetOperatingAssets_Rank == -Inf, NetOperatingAssets_Rank := NA]
Data[, Accruals_Rank := normalize_range(rank(Accruals, na.last="keep", ties.method = "max")), by = date]
Data[Accruals_Rank == Inf | Accruals_Rank == -Inf, Accruals_Rank := NA]
Data[, InvestmentToAsset_Rank := normalize_range(rank(InvestmentToAsset, na.last="keep", ties.method = "max")), by = date]
Data[InvestmentToAsset_Rank == Inf | InvestmentToAsset_Rank == -Inf, InvestmentToAsset_Rank := NA]
Data[, NetStockIssues_Rank := normalize_range(rank(NetStockIssues, na.last="keep", ties.method = "max")), by = date]
Data[NetStockIssues_Rank == Inf | NetStockIssues_Rank == -Inf, NetStockIssues_Rank := NA]
Data[, CompositeEquity_Log_Rank := normalize_range(rank(CompositeEquity_Log, na.last="keep", ties.method = "max")), by = date]
Data[CompositeEquity_Log_Rank == Inf | CompositeEquity_Log_Rank == -Inf, CompositeEquity_Log_Rank := NA]
Data[, MomentumReturn_Rank := normalize_range(rank(-MomentumReturn, na.last="keep", ties.method = "min")), by = date]
Data[MomentumReturn_Rank == Inf | MomentumReturn_Rank == -Inf, MomentumReturn_Rank := NA]
Data[, O_Score_Rank := normalize_range(rank(O_Score, na.last="keep", ties.method = "max")), by = date]
Data[O_Score_Rank == Inf | O_Score_Rank == -Inf, O_Score_Rank := NA]
# Total mispricing score is only calculated if at least 5 anomalies for the given observation are non-missing (i.e. != NA)
# Hence, creation of NA count per anomaly and observation is required
Data[, Number_RanK_NAs := 0]
Data[, Number_RanK_NAs := apply(.SD, 1, function(x) sum(is.na(x))),
.SDcols = c("GPtoAsset_Rank", "ROA_Rank", "AssetGrowth_Rank", "NetOperatingAssets_Rank","Accruals_Rank",
"InvestmentToAsset_Rank", "NetStockIssues_Rank", "CompositeEquity_Log_Rank", "MomentumReturn_Rank",
"O_Score_Rank")]
Data[Number_RanK_NAs < 6, Total_Mispricing_Score := apply(.SD, 1, mean, na.rm = T),
.SDcols = c("GPtoAsset_Rank", "ROA_Rank", "AssetGrowth_Rank", "NetOperatingAssets_Rank","Accruals_Rank",
"InvestmentToAsset_Rank", "NetStockIssues_Rank", "CompositeEquity_Log_Rank", "MomentumReturn_Rank",
"O_Score_Rank")]
Data[, Total_Mispricing_Score := normalize_range(Total_Mispricing_Score), by = date]
Data <- Data[, -c("GPtoAsset_Rank", "ROA_Rank", "AssetGrowth_Rank", "NetOperatingAssets_Rank", "Accruals_Rank",
"InvestmentToAsset_Rank", "NetStockIssues_Rank", "CompositeEquity_Log_Rank", "MomentumReturn_Rank",
"O_Score_Rank", "Number_RanK_NAs")]
return(Data)
}
US_Data_long_ST <- total_mispricing(US_Data_long_ST)
View(US_Data_long_ST)
US_Data_long_ST[, Decile := ntile(Total_Mispricing_Score, 10)]
# Calculate the value-weighted returns for the 1st and 10th deciles for each end-of-month
spread_returns <- US_Data_long_ST[Decile %in% c(1, 10), .(
Long_Return = sum(RET_USD * (LagMV_USD / sum(LagMV_USD[Decile == 10], na.rm = TRUE)) * (Decile == 10), na.rm = TRUE), # only rows of the 10th decile contribute to the sum
Short_Return = sum(RET_USD * (LagMV_USD / sum(LagMV_USD[Decile == 1], na.rm = TRUE)) * (Decile == 1), na.rm = TRUE)
), by = date]
# Calculate the spread (difference) between long and short returns for each end-of-month
spread_returns[, Spread := Long_Return - Short_Return]
View(spread_returns)
anomalyVariables <- c("GPtoAsset", "ROA", "AssetGrowth", "NetOperatingAssets", "Accruals", "InvestmentToAsset",
"NetStockIssues", "CompositeEquity_Log", "MomentumReturn", "O_Score")
createLongShortStrategies <- function(data_long, anomalyVariables) {
setDT(data_long)
# Initialize the data table to store the a list for individual anomaly strategies and combined results
strategies <- data.table(date = unique(data_long$date))
combiList <- list()
for (anomalyVariable in anomalyVariables) {
# Calculate deciles based on the Total_Mispricing_Score
US_Data_long_ST[, Decile := ntile(Total_Mispricing_Score, 10)]
# Calculate the monthly value-weighted returns for the 1st and 10th deciles
spread_returns <- US_Data_long_ST[Decile %in% c(1, 10), .(
Long_Return = sum(RET_USD * (LagMV_USD / sum(LagMV_USD[Decile == 10], na.rm = TRUE)) * (Decile == 10), na.rm = TRUE), # only rows of the 10th decile contribute to the sum
Short_Return = sum(RET_USD * (LagMV_USD / sum(LagMV_USD[Decile == 1], na.rm = TRUE)) * (Decile == 1), na.rm = TRUE)
), by = date]
# Calculate the spread (difference) between long and short returns for each end-of-month
spread_returns[, Spread := Long_Return - Short_Return]
# Store the results with the tidy names
colNames <- c(sprintf("Long_%s", anomalyVariable), sprintf("Short_%s", anomalyVariable), sprintf("Spread_%s", anomalyVariable))
spread_returns[, (colNames) := .(Long_Return, Short_Return, Spread)]
strategies <- merge(strategies, spread_returns[, .(date, Long_Return, Short_Return, Spread)], by = "date", all.x = TRUE, suffixes = c("", paste0("_", anomalyVariable)))
setnames(strategies, old = c("Long_Return", "Short_Return", "Spread"), new = colNames)
# Add to combiList for combination strategy calculation
spread_returns_normalized <- spread_returns[, .(date, Long_Return, Short_Return, Spread)]
combiList[[anomalyVariable]] <- spread_returns_normalized
}
# Calculate the combination strategy and merge into data table
# Combine all strategies into one data table
combinedStrategies <- rbindlist(combiList, idcol = "anomalyID")
# Calculate the mean of Long, Short, and Spread across all anomalies for each date as COMBI returns
combination <- combinedStrategies[, .(
Long_COMBI = mean(Long_Return, na.rm = TRUE),
Short_COMBI = mean(Short_Return, na.rm = TRUE),
Spread_COMBI = mean(Spread, na.rm = TRUE)
), by = .(date)]
strategies <- merge(strategies, combination, by = "date", all.x = TRUE)
return(strategies)
}
US_strategies <- createLongShortStrategies(US_Data_long_ST, anomalyVariables)
View(US_strategies)
US_Merged_Data <- fread("C:/Data/Mispricing/Filtered Merged Sample Data.csv")
US_Merged_Data[, date := as.character(date)]
setDT(US_Merged_Data)
setDT(US_strategies)
ex_cols <- grep("^ex_", names(US_Merged_Data), value = TRUE)
US_Merged_Data[, (ex_cols) := NULL]
merged_US_data <- merge(US_Merged_Data, US_strategies, by = "date", all = TRUE)
cols_to_adjust <- grep("^(Long_|Short_|Spread_)", names(merged_US_data), value = TRUE)
# Reduce RF and rename
for (col in cols_to_adjust) {
new_col_name <- paste0("ex_", col)
merged_US_data[, (new_col_name) := get(col) - RF]
}
merged_US_data[, (cols_to_adjust) := NULL] # Remove original Long_, Short_, and Spread_ columns
fwrite(merged_US_data, "C:/Data/Mispricing/merged_US_data.csv")
View(merged_US_data)
library(sandwich)
library(lmtest)
data <- read.csv("C:/Data/Mispricing/merged_US_data.csv", header = TRUE, sep = ",")
# Transfer all units for benchmark factors and anomaly excess returns to percent
data[, 2:5] <- data[, 2:5] * 100
data[, 9:41] <- data[, 9:41] * 100
# Categorize the anomaly excess return based on the strategies
long_cols <- names(data[,c(9,12,15,18,21,24,27,30,33,36,39)])  # Anomaly excess returns on the long leg
short_cols <- names(data[,c(10,13,16,19,22,25,28,31,34,37,40)])   # Anomaly excess returns on the short leg
spread_cols <- names(data[,c(11,14,17,20,23,26,29,32,35,38,41)])  # Anomaly excess returns spreads
colx <- names(data[,9:41])  # Anomaly excess returns
########### - From Table 1 to Table 5 - ###########
# All t-statistics based on White standard error/robust standard error
## Table 1 Panel A: Correlation matrix among the long-short benchmark-adjusted returns for 11 anomalies
residual_matrix <- matrix(NA, nrow = nrow(data), ncol = length(spread_cols))  # Create an empty matrix to store residuals
for (i in seq_along(spread_cols)) {
model1A <- as.formula(paste0((spread_cols)[i], " ~ Mkt.RF + SMB + HML"))  # Fit a linear regression model
fit1A <- lm(model1A, data = data[complete.cases(data[, c((spread_cols)[i], "Mkt.RF", "SMB", "HML")]), ])
residual_matrix[complete.cases(data[, c((spread_cols)[i], "Mkt.RF", "SMB", "HML")]), i] <- residuals(fit1A)
}
cor_matrix <- round(cor(residual_matrix, use = "complete.obs"), 2) # Correlation matrix for the residuals
# Make the correlation matrix tidy
lower_triangular <- cor_matrix
lower_triangular[upper.tri(lower_triangular)] <- NA
print(lower_triangular, na.print="")
perform_t_test <- function(colx) {
result1B <- data.frame(Anomaly = character(length(colx)),
Mean = numeric(length(colx)),
t_statistic = numeric(length(colx)),
stringsAsFactors = FALSE)  # ensures that character strings are not converted to factors
for (i in seq_along(colx)) {
anomaly <- colx[i]
data_subset <- data[[anomaly]][complete.cases(data[[anomaly]])]
model1B <- lm(data_subset ~ 1)  # Model with only the intercept
robust_se <- sqrt(diag(vcovHC(model1B, type = "HC1")))  # robust SE (the heteroskedasticity-consistent covariance matrix)
result1B[i, "Anomaly"] <- anomaly
result1B[i, "Mean"] <- round(coef(model1B)[1], 2)  # Intercept is the mean
t_value <- coef(model1B)[1] / robust_se  # t-statistic
result1B[i, "t_statistic"] <- round(t_value, 2)
}
return(result1B)
}
result1B_spread <- perform_t_test(spread_cols)   # long minus short
print(result1B_spread)
library(dplyr)
library(data.table)
USA_mispricing <- fread("C:/Data/Mispricing/usa_mispricing.csv")
# 1. Set the required sample period (All anomalies from 196507 to 200801, but OSCORE and ROA from 197201)
USA_mispricing_Period <- USA_mispricing[USA_mispricing$eom >= 19650731 & USA_mispricing$eom <= 20080131 & !USA_mispricing$size_grp %in% c("micro", "nano"), ]
USA_mispricing_Period[eom < 19720131, c("o_score", "niq_at") := .(NA_real_, NA_real_)]
# 2. Set the required sample period (All anomalies from 199801 to 202012)
#USA_mispricing_Period <- USA_mispricing[USA_mispricing$eom >= 19980131 & USA_mispricing$eom <= 20201231 & !USA_mispricing$size_grp %in% c("micro", "nano"), ]
#colnames(USA_mispricing_Period)
setnames(USA_mispricing_Period, old = c(  "me",    "me_lag1",   "ret",    "o_score",     "ret_12_1",     "gp_at", "niq_at",  "chcsho_12m",        "eqnpo_12m",     "oaccruals_at",     "noa_at",          "at_gr1",      "ppeinv_gr1a"),
new = c("MV_USD", "LagMV_USD", "RET_USD", "O_Score", "MomentumReturn", "GPtoAsset", "ROA", "NetStockIssues", "CompositeEquity_Log", "Accruals", "NetOperatingAssets",  "AssetGrowth", "InvestmentToAsset"))
US_Data_long_ST <- USA_mispricing_Period[,.(id, eom, size_grp, MV_USD, LagMV_USD, RET_USD,
GPtoAsset, ROA, AssetGrowth, NetOperatingAssets, Accruals, InvestmentToAsset,
NetStockIssues, CompositeEquity_Log, MomentumReturn, O_Score)]
US_Data_long_ST[, date := format(as.Date(as.character(eom), "%Y%m%d"), "%Y%m")]
US_Data_long_ST[, eom := NULL]
normalize_range <- function(x) {
output <- (x - min(x, na.rm = T)) / ( max(x, na.rm = T) - min(x, na.rm = T))
return(output)
}
total_mispricing <- function(Data) {
# Calculation of normalized ranks
# the anomaly degree higher -> the rank (inversely related to the average abnormal return) lower -> the anomaly return higher
Data[, GPtoAsset_Rank := normalize_range(rank(-GPtoAsset, na.last="keep", ties.method = "min")), by = date]
Data[GPtoAsset_Rank == Inf | GPtoAsset_Rank == -Inf, GPtoAsset_Rank := NA]
Data[, ROA_Rank := normalize_range(rank(-ROA, na.last="keep", ties.method = "min")), by = date]
Data[ROA_Rank == Inf | ROA_Rank == -Inf, ROA_Rank := NA]
# the anomaly degree higher -> the rank (inversely related to the average abnormal return) higher -> the anomaly return lower
Data[, AssetGrowth_Rank := normalize_range(rank(AssetGrowth, na.last="keep", ties.method = "max")), by = date]
Data[AssetGrowth_Rank == Inf | AssetGrowth_Rank == -Inf, AssetGrowth_Rank := NA]
Data[, NetOperatingAssets_Rank := normalize_range(rank(NetOperatingAssets, na.last="keep", ties.method = "max")), by = date]
Data[NetOperatingAssets_Rank == Inf | NetOperatingAssets_Rank == -Inf, NetOperatingAssets_Rank := NA]
Data[, Accruals_Rank := normalize_range(rank(Accruals, na.last="keep", ties.method = "max")), by = date]
Data[Accruals_Rank == Inf | Accruals_Rank == -Inf, Accruals_Rank := NA]
Data[, InvestmentToAsset_Rank := normalize_range(rank(InvestmentToAsset, na.last="keep", ties.method = "max")), by = date]
Data[InvestmentToAsset_Rank == Inf | InvestmentToAsset_Rank == -Inf, InvestmentToAsset_Rank := NA]
Data[, NetStockIssues_Rank := normalize_range(rank(NetStockIssues, na.last="keep", ties.method = "max")), by = date]
Data[NetStockIssues_Rank == Inf | NetStockIssues_Rank == -Inf, NetStockIssues_Rank := NA]
Data[, CompositeEquity_Log_Rank := normalize_range(rank(CompositeEquity_Log, na.last="keep", ties.method = "max")), by = date]
Data[CompositeEquity_Log_Rank == Inf | CompositeEquity_Log_Rank == -Inf, CompositeEquity_Log_Rank := NA]
Data[, MomentumReturn_Rank := normalize_range(rank(-MomentumReturn, na.last="keep", ties.method = "min")), by = date]
Data[MomentumReturn_Rank == Inf | MomentumReturn_Rank == -Inf, MomentumReturn_Rank := NA]
Data[, O_Score_Rank := normalize_range(rank(O_Score, na.last="keep", ties.method = "max")), by = date]
Data[O_Score_Rank == Inf | O_Score_Rank == -Inf, O_Score_Rank := NA]
# Total mispricing score is only calculated if at least 5 anomalies for the given observation are non-missing (i.e. != NA)
Data[, Number_RanK_NAs := 0]
Data[, Number_RanK_NAs := apply(.SD, 1, function(x) sum(is.na(x))),
.SDcols = c("GPtoAsset_Rank", "ROA_Rank", "AssetGrowth_Rank", "NetOperatingAssets_Rank","Accruals_Rank",
"InvestmentToAsset_Rank", "NetStockIssues_Rank", "CompositeEquity_Log_Rank", "MomentumReturn_Rank",
"O_Score_Rank")]
# -> Count_NA < 6 -> Calculate the total mispricing score as the average of all the non-missing anomaly ranks
Data[Number_RanK_NAs < 6, Total_Mispricing_Score := apply(.SD, 1, mean, na.rm = T),
.SDcols = c("GPtoAsset_Rank", "ROA_Rank", "AssetGrowth_Rank", "NetOperatingAssets_Rank","Accruals_Rank",
"InvestmentToAsset_Rank", "NetStockIssues_Rank", "CompositeEquity_Log_Rank", "MomentumReturn_Rank",
"O_Score_Rank")]
# Normalize the Total Mispricing Score by date
Data[, Total_Mispricing_Score := normalize_range(Total_Mispricing_Score), by = date]
Data <- Data[, -c("GPtoAsset_Rank", "ROA_Rank", "AssetGrowth_Rank", "NetOperatingAssets_Rank", "Accruals_Rank",
"InvestmentToAsset_Rank", "NetStockIssues_Rank", "CompositeEquity_Log_Rank", "MomentumReturn_Rank",
"O_Score_Rank", "Number_RanK_NAs")]
return(Data)
}
US_Data_long_ST <- total_mispricing(US_Data_long_ST)
View(US_Data_long_ST)
anomalyVariables <- c("GPtoAsset", "ROA", "AssetGrowth", "NetOperatingAssets", "Accruals", "InvestmentToAsset",
"NetStockIssues", "CompositeEquity_Log", "MomentumReturn", "O_Score")
createLongShortStrategies <- function(data_long, anomalyVariables) {
setDT(data_long)
# Anomalies for which higher values mean a lower rank (inverse relationship)
inverseAnomalies <- c("GPtoAsset", "ROA", "MomentumReturn")
strategiesList <- list()
for (anomaly in anomalyVariables) {
rankDirection <- ifelse(anomaly %in% inverseAnomalies, -1, 1) # Determine ranking direction
# Rank stocks based on each anomaly
anomalyRankColumn <- paste0(anomaly, "_Rank")
data_long[, (anomalyRankColumn) := rank(rankDirection * get(anomaly), ties.method = "first"), by = date]
# Divide into deciles based on ranks
data_long[, paste0(anomaly, "_Decile") := ntile(get(anomalyRankColumn), 10), by = date]
# Calculate value-weighted returns for each decile
data_long[, paste0(anomaly, "_ValueWeightedReturn") := RET_USD * LagMV_USD / sum(LagMV_USD, na.rm = TRUE), by = .(date, get(paste0(anomaly, "_Decile")))]
# Aggregate value-weighted returns by decile
decile_returns <- data_long[, .(DecileReturn = sum(get(paste0(anomaly, "_ValueWeightedReturn")))), by = .(date, get(paste0(anomaly, "_Decile")))]
# Identify long and short legs
long_leg <- decile_returns[get(paste0(anomaly, "_Decile")) == 10, .(date, LongReturn = DecileReturn)]
short_leg <- decile_returns[get(paste0(anomaly, "_Decile")) == 1, .(date, ShortReturn = DecileReturn)]
# Calculate the strategy return
strategy_returns <- merge(long_leg, short_leg, by = "date", all = TRUE)
strategy_returns[, paste0("Spread_", anomaly) := LongReturn - ShortReturn]
# Rename for clarity
setnames(strategy_returns, old = c("LongReturn", "ShortReturn"), new = c(paste0("Long_", anomaly), paste0("Short_", anomaly)))
# Store the results
strategiesList[[anomaly]] <- strategy_returns
}
# Combine all strategies into one data.table
combinedStrategies <- Reduce(function(x, y) merge(x, y, by = "date", all = TRUE), strategiesList)
return(combinedStrategies)
}
US_Strategies <- createLongShortStrategies(US_Data_long_ST, anomalyVariables)
anomalyVariables <- c("GPtoAsset", "ROA", "AssetGrowth", "NetOperatingAssets", "Accruals", "InvestmentToAsset",
"NetStockIssues", "CompositeEquity_Log", "MomentumReturn", "O_Score")
library(dplyr)
library(data.table)
USA_mispricing <- fread("C:/Data/Mispricing/usa_mispricing.csv")
# 1. Set the required sample period (All anomalies from 196507 to 200801, but OSCORE and ROA from 197201)
USA_mispricing_Period <- USA_mispricing[USA_mispricing$eom >= 19650731 & USA_mispricing$eom <= 20080131 & !USA_mispricing$size_grp %in% c("micro", "nano"), ]
USA_mispricing_Period[eom < 19720131, c("o_score", "niq_at") := .(NA_real_, NA_real_)]
# 2. Set the required sample period (All anomalies from 199801 to 202012)
#USA_mispricing_Period <- USA_mispricing[USA_mispricing$eom >= 19980131 & USA_mispricing$eom <= 20201231 & !USA_mispricing$size_grp %in% c("micro", "nano"), ]
#colnames(USA_mispricing_Period)
setnames(USA_mispricing_Period, old = c(  "me",    "me_lag1",   "ret",    "o_score",     "ret_12_1",     "gp_at", "niq_at",  "chcsho_12m",        "eqnpo_12m",     "oaccruals_at",     "noa_at",          "at_gr1",      "ppeinv_gr1a"),
new = c("MV_USD", "LagMV_USD", "RET_USD", "O_Score", "MomentumReturn", "GPtoAsset", "ROA", "NetStockIssues", "CompositeEquity_Log", "Accruals", "NetOperatingAssets",  "AssetGrowth", "InvestmentToAsset"))
USA_mispricing_Period[, date := format(as.Date(as.character(eom), "%Y%m%d"), "%Y%m")]
USA_mispricing_Period[, eom := NULL]
###################################################### Mispricing Measures #################################################
# Total Mispricing Score (the degree of monthly mispricng of each stock)
# Normalize by scale to range between 0 and 1
normalize_range <- function(x) {
output <- (x - min(x, na.rm = T)) / ( max(x, na.rm = T) - min(x, na.rm = T))
return(output)
}
total_mispricing <- function(Data) {
# Calculation of normalized ranks
# the mispricing degree (anomaly value) higher -> the rank (inversely related to the average abnormal return) lower -> the anomaly return higher
Data[, GPtoAsset_Rank := normalize_range(rank(-GPtoAsset, na.last="keep", ties.method = "min")), by = date]
Data[GPtoAsset_Rank == Inf | GPtoAsset_Rank == -Inf, GPtoAsset_Rank := NA]
Data[, ROA_Rank := normalize_range(rank(-ROA, na.last="keep", ties.method = "min")), by = date]
Data[ROA_Rank == Inf | ROA_Rank == -Inf, ROA_Rank := NA]
# the mispricing degree (anomaly value) higher -> the rank (inversely related to the average abnormal return) higher -> the anomaly return lower
Data[, AssetGrowth_Rank := normalize_range(rank(AssetGrowth, na.last="keep", ties.method = "max")), by = date]
Data[AssetGrowth_Rank == Inf | AssetGrowth_Rank == -Inf, AssetGrowth_Rank := NA]
Data[, NetOperatingAssets_Rank := normalize_range(rank(NetOperatingAssets, na.last="keep", ties.method = "max")), by = date]
Data[NetOperatingAssets_Rank == Inf | NetOperatingAssets_Rank == -Inf, NetOperatingAssets_Rank := NA]
Data[, Accruals_Rank := normalize_range(rank(Accruals, na.last="keep", ties.method = "max")), by = date]
Data[Accruals_Rank == Inf | Accruals_Rank == -Inf, Accruals_Rank := NA]
Data[, InvestmentToAsset_Rank := normalize_range(rank(InvestmentToAsset, na.last="keep", ties.method = "max")), by = date]
Data[InvestmentToAsset_Rank == Inf | InvestmentToAsset_Rank == -Inf, InvestmentToAsset_Rank := NA]
Data[, NetStockIssues_Rank := normalize_range(rank(NetStockIssues, na.last="keep", ties.method = "max")), by = date]
Data[NetStockIssues_Rank == Inf | NetStockIssues_Rank == -Inf, NetStockIssues_Rank := NA]
Data[, CompositeEquity_Log_Rank := normalize_range(rank(CompositeEquity_Log, na.last="keep", ties.method = "max")), by = date]
Data[CompositeEquity_Log_Rank == Inf | CompositeEquity_Log_Rank == -Inf, CompositeEquity_Log_Rank := NA]
Data[, MomentumReturn_Rank := normalize_range(rank(-MomentumReturn, na.last="keep", ties.method = "min")), by = date]
Data[MomentumReturn_Rank == Inf | MomentumReturn_Rank == -Inf, MomentumReturn_Rank := NA]
Data[, O_Score_Rank := normalize_range(rank(O_Score, na.last="keep", ties.method = "max")), by = date]
Data[O_Score_Rank == Inf | O_Score_Rank == -Inf, O_Score_Rank := NA]
# Total mispricing score is only calculated if at least 5 anomalies for the given observation are non-missing (i.e. != NA)
Data[, Number_RanK_NAs := 0]
Data[, Number_RanK_NAs := apply(.SD, 1, function(x) sum(is.na(x))),
.SDcols = c("GPtoAsset_Rank", "ROA_Rank", "AssetGrowth_Rank", "NetOperatingAssets_Rank","Accruals_Rank",
"InvestmentToAsset_Rank", "NetStockIssues_Rank", "CompositeEquity_Log_Rank", "MomentumReturn_Rank",
"O_Score_Rank")]
# -> Count_NA < 6 -> Calculate the total mispricing score as the average of all the non-missing anomaly ranks
Data[Number_RanK_NAs < 6, Total_Mispricing_Score := apply(.SD, 1, mean, na.rm = T),
.SDcols = c("GPtoAsset_Rank", "ROA_Rank", "AssetGrowth_Rank", "NetOperatingAssets_Rank","Accruals_Rank",
"InvestmentToAsset_Rank", "NetStockIssues_Rank", "CompositeEquity_Log_Rank", "MomentumReturn_Rank",
"O_Score_Rank")]
# Normalize the Total Mispricing Score by date
Data[, Total_Mispricing_Score := normalize_range(Total_Mispricing_Score), by = date]
Data <- Data[, -c("GPtoAsset_Rank", "ROA_Rank", "AssetGrowth_Rank", "NetOperatingAssets_Rank", "Accruals_Rank",
"InvestmentToAsset_Rank", "NetStockIssues_Rank", "CompositeEquity_Log_Rank", "MomentumReturn_Rank",
"O_Score_Rank", "Number_RanK_NAs")]
return(Data)
}
USA_mispricing_Period <- total_mispricing(USA_mispricing_Period)
US_Data_long_ST <- USA_mispricing_Period[,.(id, date, size_grp, MV_USD, LagMV_USD, RET_USD,
GPtoAsset, ROA, AssetGrowth, NetOperatingAssets, Accruals, InvestmentToAsset,
NetStockIssues, CompositeEquity_Log, MomentumReturn, O_Score, Total_Mispricing_Score)]
